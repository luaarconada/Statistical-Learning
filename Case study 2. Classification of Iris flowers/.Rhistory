knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
library(MASS)
library(e1071)
library(VGAM)
library(tidyverse)
head(iris)
class(iris)
class(irir$Petal.Width)
class(iris$Petal.Width)
# Chunk 1: global_options
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
library(MASS)
library(e1071)
library(VGAM)
library(tidyverse)
head(iris)
library(MASS)
library(e1071)
library(VGAM)
library(tidyverse)
head(iris)
# type here any simple idea to classify flowers using only one variable
geom_density(data=iris)
# type here any simple idea to classify flowers using only one variable
geom_density(data=iris)
# type here any simple idea to classify flowers using only one variable
boxplot(iris)
# type here any simple idea to classify flowers using only one variable
boxplot(iris$Sepal.Length,iris$Species)
# type here any simple idea to classify flowers using only one variable
plot(iris$Sepal.Length,iris$Species)
# type here any simple idea to classify flowers using only one variable
plot(iris$Sepal.Length,iris$Species)
# type here any simple idea to classify flowers using only one variable
plot(iris$Sepal.Length,iris$Sepal.Width)
# type here any simple idea to classify flowers using only one variable
plot(iris$Sepal.Length)
# type here any simple idea to classify flowers using only one variable
plot(iris$Sepal.Length,iris$Species)
ggplot(iris, aes(y = Sepal.Length))+ geom_boxplot(aes(fill = Species))+ theme_minimal()
ggplot(iris, aes(x = Sepal.Length, fill = Species)) + geom_density(alpha = 0.5, color = "black") + scale_fill_manual(values = c("red", "green", "blue"))
summary(iris$Sepal.Length)
summary(iris$Sepal.Length,iris$Species)
ggplot(iris, aes(y = Sepal.Length))+ geom_boxplot(aes(fill = Species))+ theme_minimal()
ggplot(iris, aes(x = Sepal.Length, fill = Species)) + geom_density(alpha = 0.5, color = "black") + scale_fill_manual(values = c("red", "green", "blue"))
# type here any simple idea to classify flowers using only one variable
plot(iris$Sepal.Length,iris$Species)
ggplot(iris, aes(y = Sepal.Length))+ geom_boxplot(aes(fill = Species))+ theme_minimal()
load("C:/Lúa/Madrid/Máster/Cuatri II/Semicuatri III/Data Tidying and Reporting/Tasks/qmnist_nist.RData")
# type here any simple idea to classify flowers using two variables
ggplot(iris, aes(x = Sepal.Width, color = Species)) + geom_boxplot() + theme_minimal()
colours.iris=c('blue','green','orange')[iris[,5]]
pairs(iris[1:4],main='Iris data set',pch=19,col=colours.iris,lower.panel=NULL)
ggplot(iris, aes(y = Petal.Width))+ geom_boxplot(aes(fill = Species))+ theme_minimal() (good performance 1D classifier)
ggplot(iris, aes(y = Petal.Width))+ geom_boxplot(aes(fill = Species))+ theme_minimal()
# type here any simple idea to classify flowers using two variables
ggplot(iris, aes(x = Sepal.Width, color = Species)) + geom_boxplot() + theme_minimal()
colours.iris=c('blue','green','orange')[iris[,5]]
pairs(iris[1:4],main='Iris data set',pch=19,col=colours.iris,lower.panel=NULL)
knitr::opts_chunk$set(echo = TRUE)
media
media=mean(iris$Sepal.Length)
pairs(iris[1:4],main='Iris data set',pch=19,col=colours.iris,lower.panel=NULL)
qda.class.Iris <- qda(Species ~ ., iris)
qda.class.Iris
library(klaR)
partimat(Species ~ ., data=iris, method="qda")
# guess here how to train LDA
lda.class.Iris <- lda(Species~.,iris)
lda.class.Iris
partimat(Species~.,data=iris,method='lda')
post.prob.qda = predict(qda.class.Iris, iris)$posterior
head(post.prob.qda)
post.prob.qda = predict(qda.class.Iris, iris)$posterior
head(post.prob.qda)
post.prob.lda = predict(lda.class.Iris, iris)$posterior
head(post.prob.lda)
post.prob.lda = predict(lda.class.Iris, iris)$posterior
post.prob.lda)
post.prob.lda = predict(lda.class.Iris, iris)$posterior
post.prob.lda
colors.qda.iris.good.bad <- c("black","red")[1*(iris[,5]==pred.qda)+1]
pred.qda = colnames(post.prob.qda)[apply(post.prob.qda,1,which.max)]
pred.lda = colnames(post.prob.lda)[apply(post.prob.lda,1,which.max)]
colors.qda.iris.good.bad <- c("black","red")[1*(iris[,5]==pred.qda)+1]
pairs(iris[,1:4],main="Bad (in black) classifications for Iris flowers with QDA",pch=19,col=colors.qda.iris.good.bad,lower.panel=NULL)
colors.lda.iris.good.bad <- c("black","red")[1*(iris[,5]==pred.lda)+1]
pairs(iris[,1:4],main="Bad (in black) classifications for Iris flowers with LDA",pch=19,col=colors.qda.iris.good.bad,lower.panel=NULL)
colors.qda.iris.good.bad <- c("black","red")[1*(iris[,5]==pred.qda)+1]
pairs(iris[,1:4],main="Bad (in black) classifications for Iris flowers with QDA",pch=19,col=colors.qda.iris.good.bad,lower.panel=NULL)
colors.lda.iris.good.bad <- c("black","red")[1*(iris[,5]==pred.lda)+1]
pairs(iris[,1:4],main="Bad (in black) classifications for Iris flowers with LDA",pch=19,col=colors.qda.iris.good.bad,lower.panel=NULL)
colors.qda.iris.good.bad <- c("black","red")[1*(iris[,5]==pred.qda)+1]
pairs(iris[,1:4],main="Bad (in black) classifications for Iris flowers with QDA",pch=19,col=colors.qda.iris.good.bad,lower.panel=NULL)
colors.lda.iris.good.bad <- c("black","red")[1*(iris[,5]==pred.lda)+1]
pairs(iris[,1:4],main="Bad (in black) classifications for Iris flowers with LDA",pch=19,col=colors.lda.iris.good.bad,lower.panel=NULL)
colors.qda.iris.good.bad <- c("black","red")[1*(iris[,5]==pred.qda)+1]
pairs(iris[,1:4],main="Bad (in black) classifications for Iris flowers with QDA",pch=19,col=colors.qda.iris.good.bad,lower.panel=NULL)
confMat.qda = table(pred.qda,iris$Species)
confMat.qda
n=dim(iris)[1]
error.qda=(n-sum(diag(confMat.qda)))/n
error.qda
confMat.lda = table(pred.lda,iris$Species)
confMat.lda
n=dim(iris)[1]
error.lda=(n-sum(diag(confMat.lda)))/n
error.lda
pred.qda = predict(qda.class.Iris, iris)$class
head(pred.qda)
pred.lda = predict(lda.class.Iris, iris)$class
head(pred.lda)
colors.qda.iris.good.bad <- c("black","red")[1*(iris[,5]==pred.qda)+1]
pairs(iris[,1:4],main="Bad (in black) classifications for Iris flowers with QDA",pch=19,col=colors.qda.iris.good.bad,lower.panel=NULL)
colors.lda.iris.good.bad <- c("black","red")[1*(iris[,5]==pred.lda)+1]
pairs(iris[,1:4],main="Bad (in black) classifications for Iris flowers with LDA",pch=19,col=colors.lda.iris.good.bad,lower.panel=NULL)
confMat.qda = table(pred.qda,iris$Species)
confMat.qda
n=dim(iris)[1]
error.qda=(n-sum(diag(confMat.qda)))/n
error.qda
confMat.lda = table(pred.lda,iris$Species)
confMat.lda
n=dim(iris)[1]
error.lda=(n-sum(diag(confMat.lda)))/n
error.lda
auxTrue = 0
for(i in 1:n){
# Estimation: use all data except i-th
lda.class.Iris <- lda(Species ~ ., iris[-i,])
# Prediction: use just observatin i-th
pred = predict(lda.class.Iris, iris[i, ])$class
# true labels
true = iris$Species[i]
if (pred==true) auxTrue = auxTrue + 1
}
prop.errors <- (n - auxTrue) / n
prop.errors
lda.class.Iris <- lda(Species ~ ., iris, prior = c(1,1,1)/3, CV=TRUE)
ConfMat = table(iris[,5], lda.class.Iris$class)
ConfMat
prop.errors <- (n - sum(diag(ConfMat))) / n
prop.errors
lda.class.Iris <- lda(Species ~ ., iris, prior = c(1,1,1)/3, CV=TRUE)
ConfMat = table(iris[,5], lda.class.Iris$class)
ConfMat
prop.errors <- (n - sum(diag(ConfMat))) / n
prop.errors
lda.class.Iris <- lda(Species ~ ., iris, prior = c(1,1,1)/3, CV=TRUE)
ConfMat = table(iris[,5], lda.class.Iris$class)
ConfMat
prop.errors <- (n - sum(diag(ConfMat))) / n
prop.errors
err.out=matrix(NA,nrow=100,ncol=3)
for(i in 1:100){
train <- sample(1:150, 150*0.8)  # 80% of the sample for training
n.test = 150*0.2
table(iris$Species[train])   # this is the training set
# note proportions change
# this is why it's convenient to assign equal prior probabilities,
# unless we have better prior knowledge...
# train
lda.class <- lda(Species ~ ., iris, subset = train)
qda.class <- qda(Species ~ ., iris, subset = train)
naive.class <- naiveBayes(Species ~ ., iris, subset = train)
# predict
pred.lda = predict(lda.class, iris[-train, ])$class
pred.qda = predict(qda.class, iris[-train, ])$class
pred.naive = predict(naive.class, iris[-train, ])
# test
ConfMat.lda = table(pred.lda, iris$Species[-train])
err.lda <- (n.test - sum(diag(ConfMat.lda))) / n.test
ConfMat.qda = table(pred.qda, iris$Species[-train])
err.qda <- (n.test - sum(diag(ConfMat.qda))) / n.test
ConfMat.naive = table(pred.naive, iris$Species[-train])
err.naive <- (n.test - sum(diag(ConfMat.naive))) / n.test
err.out[i,1] <- err.lda
err.out[i,2] <- err.qda
err.out[i,3] <- err.naive
}
boxplot(err.out,col="blue",xlab="", ylab="testing error", names=c("lda","qda","naive"))
apply(err.out,2,mean)
